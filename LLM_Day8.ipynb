#  Install dependencies
!pip install sentence-transformers faiss-cpu scikit-learn



#  Mini Semantic Search Demo (Day 8 ‚Äì LLM Journey)

#
# -----------------------------
# Imports
# -----------------------------
from sentence_transformers import SentenceTransformer
from sklearn.datasets import fetch_20newsgroups
import faiss
import numpy as np

# -----------------------------
#  Load Embedding Model
# -----------------------------
model = SentenceTransformer("all-MiniLM-L6-v2")

# -----------------------------
# üìù Load Real Dataset (20 Newsgroups)
# -----------------------------
categories = ['sci.med', 'comp.graphics', 'rec.sport.baseball']
newsgroups = fetch_20newsgroups(
    subset='train',
    categories=categories,
    remove=('headers', 'footers', 'quotes')
)

documents = newsgroups.data[:200]  # Take first 200 docs for demo
print(f"Loaded {len(documents)} documents")
print("\nSample Document:\n", documents[0][:300])  # preview first 300 chars

# -----------------------------
#  Encode Documents into Embeddings
# -----------------------------
doc_embeddings = model.encode(documents, show_progress_bar=True)

# -----------------------------
#  Build FAISS Index
# -----------------------------
dimension = doc_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(doc_embeddings))

# -----------------------------
#  Semantic Search Function
# -----------------------------
def semantic_search(query, top_k=5):
    query_vec = model.encode([query])
    distances, indices = index.search(query_vec, top_k)
    results = [(documents[i], distances[0][j]) for j, i in enumerate(indices[0])]
    return results

# -----------------------------
# üöÄ Run a Test Query
# -----------------------------
query = "doctor treating patients"
results = semantic_search(query, top_k=5)

print(f"Query: {query}\n")
for res, dist in results:
    print(f"- {res[:200]}... (score: {dist:.4f})\n")





# üîé Interactive Query
while True:
    query = input("Enter your search query (or 'exit' to quit): ")
    if query.lower() == "exit":
        break
    
    results = semantic_search(query, top_k=5)
    print(f"\nQuery: {query}\n")
    for res, dist in results:
        print(f"- {res[:200]}... (score: {dist:.4f})\n")
